{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"wandb_test.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"authorship_tag":"ABX9TyMYtFRbT9mVtas1a5+aiMJn"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"4d7a9315fa3a4acf895fe902554f6193":{"model_module":"@jupyter-widgets/controls","model_name":"VBoxModel","model_module_version":"1.5.0","state":{"_view_name":"VBoxView","_dom_classes":[],"_model_name":"VBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_40ed5fca21f840788ecd2e1d4d32c461","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_a86670eeaacc4cc6ae4c8b9e6ab07c99","IPY_MODEL_2bbe9ae0fe94408bbb97c46411c105e3"]}},"40ed5fca21f840788ecd2e1d4d32c461":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a86670eeaacc4cc6ae4c8b9e6ab07c99":{"model_module":"@jupyter-widgets/controls","model_name":"LabelModel","model_module_version":"1.5.0","state":{"_view_name":"LabelView","style":"IPY_MODEL_028c99091ec94b9db762f34a8231cf45","_dom_classes":[],"description":"","_model_name":"LabelModel","placeholder":"â€‹","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 0.04MB of 0.04MB uploaded (0.00MB deduped)\r","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_3665cd98545c46f49d1c844592d152a9"}},"2bbe9ae0fe94408bbb97c46411c105e3":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_b38793937e0f4f53aedd0b5cdaa710dc","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_a3372632b5a54771b50a2e38b4ed4c32"}},"028c99091ec94b9db762f34a8231cf45":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"3665cd98545c46f49d1c844592d152a9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b38793937e0f4f53aedd0b5cdaa710dc":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"a3372632b5a54771b50a2e38b4ed4c32":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rgv81EviiuG0","executionInfo":{"status":"ok","timestamp":1638455968525,"user_tz":-60,"elapsed":548,"user":{"displayName":"tim kircher","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10910350068498886043"}},"outputId":"bceb8a29-9d53-47d6-a7e0-5b0c5ee1eed4"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4umMFuf03eRZ","executionInfo":{"status":"ok","timestamp":1638455974196,"user_tz":-60,"elapsed":3217,"user":{"displayName":"tim kircher","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10910350068498886043"}},"outputId":"2b32f6cd-c3b9-4a65-e9ac-7bd9aad35bda"},"source":["!pip install wandb --upgrade"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: wandb in /usr/local/lib/python3.7/dist-packages (0.12.7)\n","Requirement already satisfied: GitPython>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.1.24)\n","Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.3)\n","Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (0.4.0)\n","Requirement already satisfied: configparser>=3.8.1 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.1.0)\n","Requirement already satisfied: shortuuid>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.0.8)\n","Requirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.15.0)\n","Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.4.8)\n","Requirement already satisfied: subprocess32>=3.5.3 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.5.4)\n","Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.23.0)\n","Requirement already satisfied: yaspin>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.1.0)\n","Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.5.0)\n","Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (7.1.2)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from wandb) (3.13)\n","Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.8.2)\n","Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.17.3)\n","Requirement already satisfied: pathtools in /usr/local/lib/python3.7/dist-packages (from wandb) (0.1.2)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb) (3.10.0.2)\n","Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb) (4.0.9)\n","Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.7/dist-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb) (5.0.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2021.10.8)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (3.0.4)\n","Requirement already satisfied: termcolor<2.0.0,>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from yaspin>=1.0.0->wandb) (1.1.0)\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3ZGdoD086SrK","executionInfo":{"status":"ok","timestamp":1638455991631,"user_tz":-60,"elapsed":15115,"user":{"displayName":"tim kircher","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10910350068498886043"}},"outputId":"7bc4092b-5c6f-430a-fbf5-deb83a173f7a"},"source":["%cd /content/drive/My Drive/Github/selfiespredict\n","! pip install -e ."],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/My Drive/Github/selfiespredict\n","Obtaining file:///content/drive/My%20Drive/Github/selfiespredict\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from selfiespredict==0.0.post1.dev51+gc5f4302) (4.8.2)\n","Requirement already satisfied: OpenNMT-py in /usr/local/lib/python3.7/dist-packages (from selfiespredict==0.0.post1.dev51+gc5f4302) (2.2.0)\n","Requirement already satisfied: selfies in /usr/local/lib/python3.7/dist-packages (from selfiespredict==0.0.post1.dev51+gc5f4302) (2.0.0)\n","Requirement already satisfied: rdkit-pypi in /usr/local/lib/python3.7/dist-packages (from selfiespredict==0.0.post1.dev51+gc5f4302) (2021.9.2.1)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from selfiespredict==0.0.post1.dev51+gc5f4302) (7.1.2)\n","Requirement already satisfied: gdown in /usr/local/lib/python3.7/dist-packages (from selfiespredict==0.0.post1.dev51+gc5f4302) (3.6.4)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from gdown->selfiespredict==0.0.post1.dev51+gc5f4302) (2.23.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from gdown->selfiespredict==0.0.post1.dev51+gc5f4302) (1.15.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from gdown->selfiespredict==0.0.post1.dev51+gc5f4302) (4.62.3)\n","Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->selfiespredict==0.0.post1.dev51+gc5f4302) (3.10.0.2)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->selfiespredict==0.0.post1.dev51+gc5f4302) (3.6.0)\n","Requirement already satisfied: tensorboard>=2.3 in /usr/local/lib/python3.7/dist-packages (from OpenNMT-py->selfiespredict==0.0.post1.dev51+gc5f4302) (2.7.0)\n","Requirement already satisfied: flask in /usr/local/lib/python3.7/dist-packages (from OpenNMT-py->selfiespredict==0.0.post1.dev51+gc5f4302) (1.1.4)\n","Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from OpenNMT-py->selfiespredict==0.0.post1.dev51+gc5f4302) (1.10.0+cu111)\n","Requirement already satisfied: configargparse in /usr/local/lib/python3.7/dist-packages (from OpenNMT-py->selfiespredict==0.0.post1.dev51+gc5f4302) (1.5.3)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from OpenNMT-py->selfiespredict==0.0.post1.dev51+gc5f4302) (3.13)\n","Requirement already satisfied: waitress in /usr/local/lib/python3.7/dist-packages (from OpenNMT-py->selfiespredict==0.0.post1.dev51+gc5f4302) (2.0.0)\n","Requirement already satisfied: torchtext==0.5.0 in /usr/local/lib/python3.7/dist-packages (from OpenNMT-py->selfiespredict==0.0.post1.dev51+gc5f4302) (0.5.0)\n","Requirement already satisfied: pyonmttok<2,>=1.23 in /usr/local/lib/python3.7/dist-packages (from OpenNMT-py->selfiespredict==0.0.post1.dev51+gc5f4302) (1.30.0)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (from torchtext==0.5.0->OpenNMT-py->selfiespredict==0.0.post1.dev51+gc5f4302) (0.1.96)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchtext==0.5.0->OpenNMT-py->selfiespredict==0.0.post1.dev51+gc5f4302) (1.19.5)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.3->OpenNMT-py->selfiespredict==0.0.post1.dev51+gc5f4302) (1.0.1)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.3->OpenNMT-py->selfiespredict==0.0.post1.dev51+gc5f4302) (0.4.6)\n","Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.3->OpenNMT-py->selfiespredict==0.0.post1.dev51+gc5f4302) (1.42.0)\n","Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.3->OpenNMT-py->selfiespredict==0.0.post1.dev51+gc5f4302) (3.17.3)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.3->OpenNMT-py->selfiespredict==0.0.post1.dev51+gc5f4302) (0.37.0)\n","Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.3->OpenNMT-py->selfiespredict==0.0.post1.dev51+gc5f4302) (0.12.0)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.3->OpenNMT-py->selfiespredict==0.0.post1.dev51+gc5f4302) (0.6.1)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.3->OpenNMT-py->selfiespredict==0.0.post1.dev51+gc5f4302) (3.3.6)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.3->OpenNMT-py->selfiespredict==0.0.post1.dev51+gc5f4302) (57.4.0)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.3->OpenNMT-py->selfiespredict==0.0.post1.dev51+gc5f4302) (1.35.0)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.3->OpenNMT-py->selfiespredict==0.0.post1.dev51+gc5f4302) (1.8.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.3->OpenNMT-py->selfiespredict==0.0.post1.dev51+gc5f4302) (4.8)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.3->OpenNMT-py->selfiespredict==0.0.post1.dev51+gc5f4302) (4.2.4)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.3->OpenNMT-py->selfiespredict==0.0.post1.dev51+gc5f4302) (0.2.8)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.3->OpenNMT-py->selfiespredict==0.0.post1.dev51+gc5f4302) (1.3.0)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.3->OpenNMT-py->selfiespredict==0.0.post1.dev51+gc5f4302) (0.4.8)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->gdown->selfiespredict==0.0.post1.dev51+gc5f4302) (2021.10.8)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->gdown->selfiespredict==0.0.post1.dev51+gc5f4302) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->gdown->selfiespredict==0.0.post1.dev51+gc5f4302) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->gdown->selfiespredict==0.0.post1.dev51+gc5f4302) (2.10)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.3->OpenNMT-py->selfiespredict==0.0.post1.dev51+gc5f4302) (3.1.1)\n","Requirement already satisfied: click<8.0,>=5.1 in /usr/local/lib/python3.7/dist-packages (from flask->OpenNMT-py->selfiespredict==0.0.post1.dev51+gc5f4302) (7.1.2)\n","Requirement already satisfied: itsdangerous<2.0,>=0.24 in /usr/local/lib/python3.7/dist-packages (from flask->OpenNMT-py->selfiespredict==0.0.post1.dev51+gc5f4302) (1.1.0)\n","Requirement already satisfied: Jinja2<3.0,>=2.10.1 in /usr/local/lib/python3.7/dist-packages (from flask->OpenNMT-py->selfiespredict==0.0.post1.dev51+gc5f4302) (2.11.3)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2<3.0,>=2.10.1->flask->OpenNMT-py->selfiespredict==0.0.post1.dev51+gc5f4302) (2.0.1)\n","Installing collected packages: selfiespredict\n","  Attempting uninstall: selfiespredict\n","    Found existing installation: selfiespredict 0.0.post1.dev51+gc5f4302\n","    Can't uninstall 'selfiespredict'. No files were found to uninstall.\n","  Running setup.py develop for selfiespredict\n","Successfully installed selfiespredict-0.0.post1.dev51+gc5f4302\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":211,"referenced_widgets":["4d7a9315fa3a4acf895fe902554f6193","40ed5fca21f840788ecd2e1d4d32c461","a86670eeaacc4cc6ae4c8b9e6ab07c99","2bbe9ae0fe94408bbb97c46411c105e3","028c99091ec94b9db762f34a8231cf45","3665cd98545c46f49d1c844592d152a9","b38793937e0f4f53aedd0b5cdaa710dc","a3372632b5a54771b50a2e38b4ed4c32"]},"id":"3lBomA0x6b9Q","executionInfo":{"status":"ok","timestamp":1638457726313,"user_tz":-60,"elapsed":12291,"user":{"displayName":"tim kircher","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10910350068498886043"}},"outputId":"76f0099b-2ae0-4dd4-dedd-16ab525ac7b6"},"source":["%cd run/model\n","import wandb\n","wandb.init(project=\"ML4Science\", entity=\"\", sync_tensorboard=True)\n","name = wandb.run.id"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[Errno 2] No such file or directory: 'run/model'\n","/content/drive/My Drive/Github/selfiespredict/run/model\n"]},{"output_type":"display_data","data":{"text/html":["Finishing last run (ID:6vhgt9bk) before initializing another..."],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"display_data","data":{"text/html":["<br/>Waiting for W&B process to finish, PID 4800... <strong style=\"color:green\">(success).</strong>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4d7a9315fa3a4acf895fe902554f6193","version_minor":0,"version_major":2},"text/plain":["VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)â€¦"]},"metadata":{}},{"output_type":"display_data","data":{"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\">\n","</div><div class=\"wandb-col\">\n","</div></div>\n","Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n","<br/>Synced <strong style=\"color:#cdcd00\">visionary-leaf-17</strong>: <a href=\"https://wandb.ai/timkircher/ML4Science/runs/6vhgt9bk\" target=\"_blank\">https://wandb.ai/timkircher/ML4Science/runs/6vhgt9bk</a><br/>\n","Find logs at: <code>./wandb/run-20211202_143959-6vhgt9bk/logs</code><br/>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"display_data","data":{"text/html":["Successfully finished last run (ID:6vhgt9bk). Initializing new run:<br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"display_data","data":{"text/html":["\n","                    Syncing run <strong><a href=\"https://wandb.ai/timkircher/ML4Science/runs/1qavxddu\" target=\"_blank\">super-flower-20</a></strong> to <a href=\"https://wandb.ai/timkircher/ML4Science\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n","\n","                "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eEPKQ3Rt_l_L","executionInfo":{"status":"ok","timestamp":1638452652205,"user_tz":-60,"elapsed":1928,"user":{"displayName":"tim kircher","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10910350068498886043"}},"outputId":"562c6db0-d5dc-4d65-8fef-8549b404725c"},"source":["! onmt_build_vocab -config test_model_params.yaml -src_seq_length 3000 -tgt_seq_length 3000 -src_vocab_size 3000 -tgt_vocab_size 3000"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Corpus corpus_1's weight should be given. We default it to 1 for you.\n","[2021-12-02 13:44:11,176 INFO] Counter vocab from 5000 samples.\n","[2021-12-02 13:44:11,176 INFO] Build vocab on 5000 transformed examples/corpus.\n","[2021-12-02 13:44:11,185 INFO] corpus_1's transforms: TransformPipe()\n","[2021-12-02 13:44:11,389 INFO] Counters src:141\n","[2021-12-02 13:44:11,389 INFO] Counters tgt:51\n","[2021-12-02 13:44:11,389 INFO] Counters after share:142\n","[2021-12-02 13:44:11,390 WARNING] path ./run/example.vocab.src exists, may overwrite...\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GxaysmY47Ntw","executionInfo":{"status":"ok","timestamp":1638457869265,"user_tz":-60,"elapsed":43815,"user":{"displayName":"tim kircher","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10910350068498886043"}},"outputId":"0f051bef-1c59-4968-b9ed-73d84a980d18"},"source":["! onmt_train -config run.yaml \\\n","        -seed 42 -gpu_ranks 0  \\\n","        -train_steps 50 -param_init 0 \\\n","        -param_init_glorot -max_generator_batches 32 \\\n","        -batch_type tokens -batch_size 6144\\\n","         -normalization tokens -max_grad_norm 0  -accum_count 4 \\\n","        -optim adam -adam_beta1 0.9 -adam_beta2 0.998 -decay_method noam  \\\n","        -warmup_steps 8000 -learning_rate 2 -label_smoothing 0.0 \\\n","        -layers 4 -rnn_size  384 -word_vec_size 384 \\\n","        -encoder_type transformer -decoder_type transformer \\\n","        -dropout 0.1 -position_encoding -share_embeddings  \\\n","        -global_attention general -global_attention_function softmax \\\n","        -self_attn_type scaled-dot -heads 8 -transformer_ff 2048 \\\n","        -report_every 10 -tensorboard True -tensorboard_log_dir log_dir"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[2021-12-02 15:10:26,136 INFO] Missing transforms field for corpus_1 data, set to default: [].\n","[2021-12-02 15:10:26,138 WARNING] Corpus corpus_1's weight should be given. We default it to 1 for you.\n","[2021-12-02 15:10:26,138 INFO] Missing transforms field for valid data, set to default: [].\n","[2021-12-02 15:10:26,139 INFO] Parsed 2 corpora from -data.\n","[2021-12-02 15:10:26,139 INFO] Get special vocabs from Transforms: {'src': set(), 'tgt': set()}.\n","[2021-12-02 15:10:26,139 INFO] Loading vocab from text file...\n","[2021-12-02 15:10:26,139 INFO] Loading src vocabulary from ./run/example.vocab.src\n","[2021-12-02 15:10:26,140 INFO] Loaded src vocab has 142 tokens.\n","[2021-12-02 15:10:26,140 INFO] Loading tgt vocabulary from ./run/example.vocab.src\n","[2021-12-02 15:10:26,141 INFO] Loaded tgt vocab has 142 tokens.\n","[2021-12-02 15:10:26,141 INFO] Building fields with vocab in counters...\n","[2021-12-02 15:10:26,142 INFO]  * tgt vocab size: 146.\n","[2021-12-02 15:10:26,142 INFO]  * src vocab size: 144.\n","[2021-12-02 15:10:26,142 INFO]  * merging src and tgt vocab...\n","[2021-12-02 15:10:26,142 INFO]  * merged vocab size: 146.\n","[2021-12-02 15:10:26,142 INFO]  * src vocab size = 146\n","[2021-12-02 15:10:26,142 INFO]  * tgt vocab size = 146\n","[2021-12-02 15:10:26,143 INFO] Building model...\n","[2021-12-02 15:10:29,212 INFO] NMTModel(\n","  (encoder): TransformerEncoder(\n","    (embeddings): Embeddings(\n","      (make_embedding): Sequential(\n","        (emb_luts): Elementwise(\n","          (0): Embedding(146, 384, padding_idx=1)\n","        )\n","        (pe): PositionalEncoding(\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","    )\n","    (transformer): ModuleList(\n","      (0): TransformerEncoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=384, out_features=384, bias=True)\n","          (linear_values): Linear(in_features=384, out_features=384, bias=True)\n","          (linear_query): Linear(in_features=384, out_features=384, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=384, out_features=384, bias=True)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=384, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=384, bias=True)\n","          (layer_norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n","          (dropout_1): Dropout(p=0.1, inplace=False)\n","          (dropout_2): Dropout(p=0.1, inplace=False)\n","        )\n","        (layer_norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (1): TransformerEncoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=384, out_features=384, bias=True)\n","          (linear_values): Linear(in_features=384, out_features=384, bias=True)\n","          (linear_query): Linear(in_features=384, out_features=384, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=384, out_features=384, bias=True)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=384, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=384, bias=True)\n","          (layer_norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n","          (dropout_1): Dropout(p=0.1, inplace=False)\n","          (dropout_2): Dropout(p=0.1, inplace=False)\n","        )\n","        (layer_norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (2): TransformerEncoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=384, out_features=384, bias=True)\n","          (linear_values): Linear(in_features=384, out_features=384, bias=True)\n","          (linear_query): Linear(in_features=384, out_features=384, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=384, out_features=384, bias=True)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=384, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=384, bias=True)\n","          (layer_norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n","          (dropout_1): Dropout(p=0.1, inplace=False)\n","          (dropout_2): Dropout(p=0.1, inplace=False)\n","        )\n","        (layer_norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (3): TransformerEncoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=384, out_features=384, bias=True)\n","          (linear_values): Linear(in_features=384, out_features=384, bias=True)\n","          (linear_query): Linear(in_features=384, out_features=384, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=384, out_features=384, bias=True)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=384, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=384, bias=True)\n","          (layer_norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n","          (dropout_1): Dropout(p=0.1, inplace=False)\n","          (dropout_2): Dropout(p=0.1, inplace=False)\n","        )\n","        (layer_norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","    )\n","    (layer_norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n","  )\n","  (decoder): TransformerDecoder(\n","    (embeddings): Embeddings(\n","      (make_embedding): Sequential(\n","        (emb_luts): Elementwise(\n","          (0): Embedding(146, 384, padding_idx=1)\n","        )\n","        (pe): PositionalEncoding(\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","    )\n","    (layer_norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n","    (transformer_layers): ModuleList(\n","      (0): TransformerDecoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=384, out_features=384, bias=True)\n","          (linear_values): Linear(in_features=384, out_features=384, bias=True)\n","          (linear_query): Linear(in_features=384, out_features=384, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=384, out_features=384, bias=True)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=384, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=384, bias=True)\n","          (layer_norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n","          (dropout_1): Dropout(p=0.1, inplace=False)\n","          (dropout_2): Dropout(p=0.1, inplace=False)\n","        )\n","        (layer_norm_1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n","        (drop): Dropout(p=0.1, inplace=False)\n","        (context_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=384, out_features=384, bias=True)\n","          (linear_values): Linear(in_features=384, out_features=384, bias=True)\n","          (linear_query): Linear(in_features=384, out_features=384, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=384, out_features=384, bias=True)\n","        )\n","        (layer_norm_2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n","      )\n","      (1): TransformerDecoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=384, out_features=384, bias=True)\n","          (linear_values): Linear(in_features=384, out_features=384, bias=True)\n","          (linear_query): Linear(in_features=384, out_features=384, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=384, out_features=384, bias=True)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=384, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=384, bias=True)\n","          (layer_norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n","          (dropout_1): Dropout(p=0.1, inplace=False)\n","          (dropout_2): Dropout(p=0.1, inplace=False)\n","        )\n","        (layer_norm_1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n","        (drop): Dropout(p=0.1, inplace=False)\n","        (context_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=384, out_features=384, bias=True)\n","          (linear_values): Linear(in_features=384, out_features=384, bias=True)\n","          (linear_query): Linear(in_features=384, out_features=384, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=384, out_features=384, bias=True)\n","        )\n","        (layer_norm_2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n","      )\n","      (2): TransformerDecoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=384, out_features=384, bias=True)\n","          (linear_values): Linear(in_features=384, out_features=384, bias=True)\n","          (linear_query): Linear(in_features=384, out_features=384, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=384, out_features=384, bias=True)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=384, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=384, bias=True)\n","          (layer_norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n","          (dropout_1): Dropout(p=0.1, inplace=False)\n","          (dropout_2): Dropout(p=0.1, inplace=False)\n","        )\n","        (layer_norm_1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n","        (drop): Dropout(p=0.1, inplace=False)\n","        (context_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=384, out_features=384, bias=True)\n","          (linear_values): Linear(in_features=384, out_features=384, bias=True)\n","          (linear_query): Linear(in_features=384, out_features=384, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=384, out_features=384, bias=True)\n","        )\n","        (layer_norm_2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n","      )\n","      (3): TransformerDecoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=384, out_features=384, bias=True)\n","          (linear_values): Linear(in_features=384, out_features=384, bias=True)\n","          (linear_query): Linear(in_features=384, out_features=384, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=384, out_features=384, bias=True)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=384, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=384, bias=True)\n","          (layer_norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n","          (dropout_1): Dropout(p=0.1, inplace=False)\n","          (dropout_2): Dropout(p=0.1, inplace=False)\n","        )\n","        (layer_norm_1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n","        (drop): Dropout(p=0.1, inplace=False)\n","        (context_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=384, out_features=384, bias=True)\n","          (linear_values): Linear(in_features=384, out_features=384, bias=True)\n","          (linear_query): Linear(in_features=384, out_features=384, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=384, out_features=384, bias=True)\n","        )\n","        (layer_norm_2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n","      )\n","    )\n","  )\n","  (generator): Sequential(\n","    (0): Linear(in_features=384, out_features=146, bias=True)\n","    (1): Cast()\n","    (2): LogSoftmax(dim=-1)\n","  )\n",")\n","[2021-12-02 15:10:29,214 INFO] encoder: 8729600\n","[2021-12-02 15:10:29,214 INFO] decoder: 11098258\n","[2021-12-02 15:10:29,214 INFO] * number of parameters: 19827858\n","[2021-12-02 15:10:31,203 INFO] Starting training on GPU: [0]\n","[2021-12-02 15:10:31,203 INFO] Start training loop and validate every 10000 steps...\n","[2021-12-02 15:10:31,203 INFO] corpus_1's transforms: TransformPipe()\n","[2021-12-02 15:10:31,203 INFO] Weighted corpora loaded so far:\n","\t\t\t* corpus_1: 1\n","[2021-12-02 15:10:38,591 INFO] Step 10/   50; acc:   0.17; ppl: 270.27; xent: 5.60; lr: 0.00000; 29358/18313 tok/s;      7 sec\n","[2021-12-02 15:10:45,376 INFO] Step 20/   50; acc:   2.31; ppl: 146.08; xent: 4.98; lr: 0.00000; 31683/20020 tok/s;     14 sec\n","[2021-12-02 15:10:52,241 INFO] Step 30/   50; acc:  26.26; ppl: 52.48; xent: 3.96; lr: 0.00000; 32314/21033 tok/s;     21 sec\n","[2021-12-02 15:10:59,247 INFO] Step 40/   50; acc:  37.11; ppl: 26.88; xent: 3.29; lr: 0.00001; 31169/19708 tok/s;     28 sec\n","[2021-12-02 15:11:06,033 INFO] Step 50/   50; acc:  35.69; ppl: 18.06; xent: 2.89; lr: 0.00001; 31991/20281 tok/s;     35 sec\n","[2021-12-02 15:11:06,037 INFO] Saving checkpoint ./run/model_step_50.pt\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JFIzkF16Z8jx","executionInfo":{"status":"ok","timestamp":1638457911330,"user_tz":-60,"elapsed":12764,"user":{"displayName":"tim kircher","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10910350068498886043"}},"outputId":"5f489a84-2724-4f02-b5fc-03888025037e"},"source":["!wandb sync -p \"ML4Science\"  --id name  ./log_dir"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 1 tfevent files in /content/drive/My Drive/Github/selfiespredict/run/model/log_dir\n","Syncing: https://wandb.ai/timkircher/ML4Science/runs/1qavxddu ...\n"]}]}]}